def scan_association(self, G):
    # WARNING: this method is not working yet
    """
    Association test.

    Let us define:

        ğ™ºâ‚€ = ğ“‹â‚(Ïâ‚ğ™´ğ™´áµ€ + (1-Ïâ‚)ğ™º) + ğ“‹â‚‚ğ™¸.

    The marginalised form of Eq. (1) can be written as

        ğ² ~ ğ“(Wğ›‚, ğ™ºâ‚ = ğ“‹â‚€ğ™³((1-Ïâ‚€)ğŸğŸáµ€ + Ïâ‚€ğ™´ğ™´áµ€)ğ™³ + ğ™ºâ‚€),

    where ğ™³ = diag(ğ ). For a given Ïâ‚€, the score test allows us to compare the hypotheses:

        ğ“—â‚€: ğ“‹â‚€ = 0
        ğ“—â‚: ğ“‹â‚€ > 0

    by first estimating the parameters ğ›‚, ğ“‹â‚, Ïâ‚, and ğ“‹â‚‚ with ğ“‹â‚€ set to zero and then defining
    the score statistic ğ‘„áµ¨ = Â½ğ²áµ€ğ™¿(âˆ‚ğ™ºâ‚)ğ™¿ğ². Under the null hypothesis, the score statistic follows
    the distribution:

        ğ‘„áµ¨ âˆ¼ âˆ‘áµ¢ğœ†áµ¢Ï‡Â²(1),

    where ğœ†áµ¢ are the non-zero eigenvalues of Â½âˆšğ™¿(âˆ‚ğ™ºâ‚)âˆšğ™¿ (given Ï=Ïâ‚€).

    Unfortunately we don't know the value of Ïâ‚€, and therefore the vanilla score test cannot be
    applied. We instead employ an alternative test defined as follows.

    - Calculate qáµ¨ = Â½ğ²áµ€ğ™¿(âˆ‚ğ™ºâ‚)ğ™¿ğ² for a set of Ïâ‚€ values. Let páµ¨ be its corresponding p-value.
    - Define the T statistic as T = min{páµ¨}.
    - Derive the distribution of T under the null hypothesis that ğ“‹â‚€=0.
    - Compute the p-value of T.

    The p-value of T will be therefore used to assess whether we have enough evidence to reject
    the hypothesis that ğ  has no effect.

    T statistic
    -----------

    It can be show that:

        Qáµ¨ âˆ¼ Â½ğœáµ¨â‹…Î·â‚€ + Â½Ïğ‘˜,

    where:

        ğœáµ¨ = ğ‘š(1-Ïâ‚€) + (Ïâ‚€/ğ‘š)ğŸáµ€ğš‰ğš‰áµ€ğ™´ğ™´áµ€ğš‰áµ€ğš‰ğŸ
        Î·â‚€ = Ï‡Â²(ğŸ·)
        ğ™¼  = (ğš‰ğŸğŸáµ€ğš‰áµ€)/ğ‘š
        ğ‘˜  âˆ¼ âˆ‘Î»â‚›â‹…Î·â‚› + Î¾                          for ğ‘ =ğŸ·, ğŸ¸, ..., ğ‘†
        Î·â‚› = Ï‡Â²(ğŸ·)

    The terms Î»â‚› are the non-zero eigenvalues of ğ™´áµ€ğš‰áµ€(ğ™¸-ğ™¼)ğš‰ğ™´. It can also be shown that the
    above (ğ‘†+2) random variables are pair-wise uncorrelated and that

        ğ”¼[Î¾]   = ğŸ
        ğ”¼[Î¾Î¾áµ€] = ğŸºâ‹…tr[ğ™´áµ€ğš‰áµ€(ğ™¸-ğ™¼)ğš‰ğ™´ğ™´áµ€ğš‰áµ€ğ™¼ğš‰ğ™´]

    The p-value of the T statistic is given by:

        P(t<T) = P(min{páµ¨} < T)
               = ğŸ· - ğ”¼[P(ğ‘˜ < min{(2â‹…q(páµ¨) - ğœáµ¨Î·â‚€) / Ï} | Î·â‚€)],

    where q(páµ¨) is the (ğŸ·-T)th percentile of the Qáµ¨ distribution and the expectation is under
    the distribution of Î·â‚€. Ideally, we would calculate

        P(t<T) = 1 - âˆ«F(g(ğ‘¥))â‹…p(Î·â‚€=ğ‘¥)â‹…dğ‘¥,

    where F(â‹…) is the cumulative distribution of ğ‘˜ and g(ğ‘¥)=min{(2â‹…q(páµ¨) - ğœáµ¨Î·â‚€) / Ï}.
    Since we do not know the distribution of Î¾, and therefore neither do we know F(â‹…), we will
    instead use the cumulative function Fáµª(â‹…) of âˆ‘Î·â‚› and adjust its mean variance accordingly:

        P(t<T) â‰ˆ 1 - âˆ«Fáµª((g(ğ‘¥)-ğœ‡)â‹…c + ğœ‡)â‹…p(Î·â‚€=ğ‘¥)â‹…dğ‘¥,

    where

        ğœ‡ = ğ”¼[ğ‘˜]
        c = âˆš(Var[ğ‘˜] - Var[Î¾])/âˆšVar[ğ‘˜].
    """
    # K0 = self._null_lmm_assoc["cov"]
    qscov = self._null_lmm_assoc["qscov"]

    # P = P_matrix(self._W, K0)
    Pmat = PMat(qscov, self._W)
    # H1 vs H0 via score test
    for gr in G.T:
        # D = diag(g)
        g = gr[:, newaxis]

        weights = []
        liu_params = []
        for rho0 in self._rho0:
            # dK = (1 - rho0) * g @ g.T + rho0 * D @ self._EE @ D
            hdK = concatenate(
                [sqrt(1 - rho0) * g, sqrt(rho0) * ddot(gr, self._E)], axis=1
            )
            ss = ScoreStatistic(Pmat, qscov, hdK)
            Q = ss.statistic(self._y)
            weights += [ss.distr_weights()]
            liu_params += [score_statistic_liu_params(Q, weights)]

        T = min(i["pv"] for i in liu_params)
        q = qmin(liu_params)
        E = self._E

        # 3. Calculate quantities that occur in null distribution
        # g has to be a column-vector
        # D = diag(gr)
        # Pg = P @ g
        Pg = Pmat.dot(g)
        m = (g.T @ Pg)[0, 0]
        # M = 1 / m * (sqrtm(P) @ g @ g.T @ sqrtm(P))
        DE = ddot(gr, E)
        # H1 = E.T @ D.T @ P @ D @ E
        H1 = DE.T @ Pmat.dot(DE)
        # H2 = E.T @ D.T @ sqrtm(P) @ M @ sqrtm(P) @ D @ E
        H2 = 1 / m * multi_dot([DE.T, Pg, Pg.T, ddot(gr, E)])
        H = H1 - H2
        lambdas = eigvalsh(H / 2)

        # eta = ETxPx11xPxE @ ZTIminusMZ

        # Z = sqrtm(P).T @ D
        # I = eye(M.shape[0])
        # eta = E.T @ Z.T @ (I - M) @ Z @ E @ E.T @ Z.T @ M @ Z @ E
        eta_left = (
            ddot(Pmat.dot(DE).T, gr) - multi_dot([DE.T, Pg, ddot(Pg.T, gr)]) / m
        )
        eta_right = multi_dot([E, DE.T, Pg, Pg.T, DE]) / m
        # eta = eta_left @ eta_right
        vareta = 4 * trace2(eta_left, eta_right)

        # OneZTZE = 0.5 * (g.T @ PxoE)
        one = ones((self._n_samples, 1))
        # tau_top = one.T @ Z.T @ Z @ self._E @ self._E.T @ Z.T @ Z @ one
        tau_top = ddot(one.T, gr) @ Pmat.dot(multi_dot([DE, DE.T, Pmat.dot(one)]))
        tau_top = tau_top[0, 0]
        tau_rho = empty(len(self._rho0))
        for i, r0 in enumerate(self._rho0):
            tau_rho[i] = (1 - r0) * m + r0 * tau_top / m

        MuQ = sum(lambdas)
        VarQ = sum(lambdas ** 2) * 2 + vareta
        KerQ = sum(lambdas ** 4) / (sum(lambdas ** 2) ** 2) * 12
        Df = 12 / KerQ

        pvalue = optimal_davies_pvalue(
            q, MuQ, VarQ, KerQ, lambdas, vareta, Df, tau_rho, self._rho0, T
        )
        # Final correction to make sure that the p-value returned is sensible
        # multi = 3
        # if len(self._rhos) < 3:
        #     multi = 2
        # idx = where(pliumod[:, 0] > 0)[0]
        # pval = pliumod[:, 0].min() * multi
        # if pvalue <= 0 or len(idx) < len(self._rhos):
        #     pvalue = pval
        # if pvalue == 0:
        #     if len(idx) > 0:
        #         pvalue = pliumod[:, 0][idx].min()
        return pvalue
