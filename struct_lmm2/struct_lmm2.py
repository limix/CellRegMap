import numpy as np
import scipy as sp
from numpy import concatenate, inf, newaxis
from numpy.linalg import eigvalsh, inv, solve
from numpy.random import RandomState
from numpy_sugar import epsilon
from numpy_sugar.linalg import ddot, economic_qs, economic_svd
from scipy.linalg import sqrtm

from chiscore import davies_pvalue, mod_liu, optimal_davies_pvalue
from glimix_core.lmm import LMM


class StructLMM2:
    r"""
    Mixed-model with genetic effect heterogeneity.

    The extended StructLMM model (two random effects) is

        ð² = ð™¼ð›‚ + ð ð›½ + ð âŠ™ð›ƒ + ðž + ð® + ð›†,                                          (1)

    where

        (ð âŠ™ð›ƒ)áµ¢ = ð áµ¢ð›ƒáµ¢
        ð›½ âˆ¼ ð“(0, ð“‹â‚€â‹…Ï),
        ð›ƒ âˆ¼ ð“(ðŸŽ, ð“‹â‚€(1-Ï)ð™´ð™´áµ€),
        ðž âˆ¼ ð“(ðŸŽ, ð“‹â‚ðš†ðš†áµ€),
        ð® ~ ð“(ðŸŽ, gÂ²ð™º), and
        ð›† âˆ¼ ð“(ðŸŽ, ð“‹â‚‚ð™¸).

    The matrices ð™´ and ðš† are generally the same, and represent the environment
    configuration for each sample.
    The parameter Ï âˆˆ [ðŸ¶, ðŸ·] dictates the relevance of genotype-environment interaction
    versus the genotype effect alone.
    The term ðž accounts for additive environment-only effects while ð›† accounts for
    noise effects.
    The term ð® accounts for population structure.

    The above model is equivalent to

        ð² = ð™¼ð›‚ + ð âŠ™ð›ƒ + ðž + ð® + ð›†,                                               (2)

    where

        ð›ƒ âˆ¼ ð“(ðŸŽ, ð“‹â‚€(ÏðŸðŸáµ€ + (1-Ï)ð™´ð™´áµ€)),
        ðž âˆ¼ ð“(ðŸŽ, ð“‹â‚ðš†ðš†áµ€),
        ð® ~ ð“(ðŸŽ, gÂ²ð™º), and
        ð›† âˆ¼ ð“(ðŸŽ, ð“‹â‚‚ð™¸).

    Notice that the ð›ƒ in Eqs. (1) and (2) are not the same.
    Its marginalised form is given by

        ð² âˆ¼ ð“(ð™¼ð›‚, ð“‹â‚€ð™³(ÏðŸðŸáµ€ + (1-Ï)ð™´ð™´áµ€)ð™³ + ð“‹â‚ðš†ðš†áµ€ + gÂ²ð™º + ð“‹â‚‚ð™¸),

    where ð™³ = diag(ð ).

    StructLMM method is used to perform two types of statistical tests.
    The association one compares the following hypotheses:

        ð“—â‚€: ð“‹â‚€ = 0
        ð“—â‚: ð“‹â‚€ > 0

    ð“—â‚€ denotes no genetic association, while ð“—â‚ models any genetic association.
    In particular, ð“—â‚ includes genotype-environment interaction as part of genetic
    association.
    The interaction test is slightly more complicated as the term ð ð›½ in Eq. (1) is now
    considered a fixed one.
    In pratice, however, we instead include ð  in the covariates matrix ð™¼ and set Ï = 0
    in Eq. (2).
    We refer to this modified model as the interaction model.
    The compared hypotheses are:

        ð“—â‚€: ð“‹â‚€ = 0 (given the interaction model)
        ð“—â‚: ð“‹â‚€ > 0 (given the interaction model)
    """

    def __init__(self, y, W, E, G=None, a_values=None, K=None):

        self.y = y
        self.E = E
        self.G = G
        self.W = W

        self.Sigma = E @ E.T

        if self.G is None:
            self.K = np.eye(self.y.shape[0])
        else:
            self.K = G @ G.T

        self.a_values = a_values
        if self.a_values is None:
            self.a_values = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]
        self.Cov = {}
        self.QS_a = {}
        for a in self.a_values:
            self.Cov[a] = a * self.Sigma + (1 - a) * self.K
            self.QS_a[a] = economic_qs(self.Cov[a])

    def fit_null(self, g):
        self.X = concatenate((self.W, g[:, newaxis]), axis=1)
        best = {"lml": -inf, "a": 0, "v0": 0, "v1": 0, "beta": 0}
        for a in self.a_values:
            # cov(y) = v0*(aÎ£ + (1-a)K) + v1*I
            lmm = LMM(self.y, self.X, self.QS_a[a], restricted=True)
            lmm.fit(verbose=False)
            if lmm.lml() > best["lml"]:
                best["lml"] = lmm.lml()
                best["a"] = a
                best["v0"] = lmm.v0
                best["v1"] = lmm.v1
                best["alpha"] = lmm.beta
                best["covariance"] = lmm.covariance()
        self.best = best

    def score_2_dof(self, g):
        alpha = self.best["alpha"][:-1]
        beta = self.best["alpha"][-1]
        # eÂ²Î£ + gÂ²K = sÂ²(aÎ£ + (1-a)K)
        # eÂ² = sÂ²*a
        # gÂ² = sÂ²*(1-a)
        s2 = self.best["v0"]  # sÂ²
        eps2 = self.best["v1"]  # ðœ€Â²

        # H1 via score test
        # Let Kâ‚€ = gÂ²K + eÂ²Î£ + ðœ€Â²I
        # with optimal values eÂ² and ðœ€Â² found above.
        K0 = self.best["covariance"]

        # Let Pâ‚€ = Kâ»Â¹ - Kâ‚€â»Â¹X(Xáµ€Kâ‚€â»Â¹X)â»Â¹Xáµ€Kâ‚€â»Â¹.
        K0iX = solve(K0, self.X)
        P0 = inv(K0) - K0iX @ solve(self.X.T @ K0iX, K0iX.T)

        # Pâ‚€ð² = Kâ»Â¹ð² - Kâ‚€â»Â¹X(Xáµ€Kâ‚€â»Â¹X)â»Â¹Xáµ€Kâ‚€â»Â¹ð².
        K0iy = solve(K0, self.y)
        P0y = K0iy - solve(K0, self.X @ solve(self.X.T @ K0iX, self.X.T @ K0iy))

        # The covariance matrix of H1 is K = Kâ‚€ + bÂ²diag(ð )â‹…Î£â‹…diag(ð )
        # We have âˆ‚K/âˆ‚bÂ² = diag(ð )â‹…Î£â‹…diag(ð )
        # The score test statistics is given by
        # Q = Â½ð²áµ€Pâ‚€â‹…âˆ‚Kâ‹…Pâ‚€ð²
        dK = ddot(g, ddot(self.Sigma, g))
        Q = (P0y.T @ dK @ P0y) / 2

        # Q is the score statistic for our interaction test and follows a linear combination
        # of chi-squared (df=1) distributions:
        # Q âˆ¼ âˆ‘Î»Ï‡Â², where Î»áµ¢ are the non-zero eigenvalues of Â½âˆšPâ‚€â‹…âˆ‚Kâ‹…âˆšPâ‚€.
        sqrP0 = sqrtm(P0)
        # lambdas = eigvalsh((sqrP0 @ dK @ sqrP0) / 2)
        # lambdas = lambdas[lambdas > epsilon.small]
        # print(lambdas)
        # print(Q)
        pval = davies_pvalue(Q, (sqrP0 @ dK @ sqrP0) / 2)
        return pval
