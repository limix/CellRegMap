from collections import namedtuple

Variances = namedtuple("Variances", "g gxe k e n")
Simulation = namedtuple(
    "Simulation", "mafs y offset beta_g y_g y_gxe y_k y_e y_n variances G E Lk K M"
)


def sample_maf(n_snps: int, maf_min: float, maf_max: float, random):
    assert maf_min <= maf_max and maf_min >= 0 and maf_max <= 1
    return random.rand(n_snps) * (maf_max - maf_min) + maf_min


def sample_genotype(n_samples: int, mafs, random):
    from numpy import asarray, stack

    G = []
    mafs = asarray(mafs, float)
    for maf in mafs:
        probs = [(1 - maf) ** 2, 1 - ((1 - maf) ** 2 + maf ** 2), maf ** 2]
        g = random.choice([0, 1, 2], p=probs, size=n_samples)
        G.append(asarray(g, float))

    return stack(G, axis=1)


def column_normalize(X):
    from numpy import asarray, errstate

    X = asarray(X, float)

    with errstate(divide="raise", invalid="raise"):
        return (X - X.mean(0)) / X.std(0)


def create_environment_matrix(
    n_samples: int, n_rep: int, n_env: int, n_env_groups: int, random
):
    from numpy.linalg import cholesky

    n = n_samples * n_rep
    E = random.randn(n, n_env)
    E = column_normalize(E)
    EE = E @ E.T
    EE /= EE.diagonal().mean()
    H = sample_covariance_matrix(E.shape[0], n_env_groups)[1]
    M = EE + H
    M /= M.diagonal().mean()
    jitter(M)
    return cholesky(M)


def sample_covariance_matrix(n_samples: int, n_groups: int):
    from numpy import array_split, zeros
    from numpy.linalg import cholesky

    G = zeros((n_samples, n_groups))
    groups = array_split(range(n_samples), n_groups)

    for i, idx in enumerate(groups):
        G[idx, i] = 1.0

    G = column_normalize(G)
    K = G @ G.T
    K /= K.diagonal().mean()
    jitter(K)

    return (cholesky(K), K)


def jitter(K):
    from numpy import errstate, eye

    with errstate(divide="raise", invalid="raise"):
        # This small diagonal offset is to guarantee the full-rankness.
        K += 1e-8 * eye(K.shape[0])

    return K


def create_variances(r0, v0, has_kinship=True) -> Variances:
    """
    Remember that:

        cov(ð²) = ð“‹â‚€(1-Ïâ‚€)ð™³ðŸðŸáµ€ð™³ + ð“‹â‚€Ïâ‚€ð™³ð™´ð™´áµ€ð™³ + ð“‹â‚Ïâ‚EEáµ€ + ð“‹â‚(1-Ïâ‚)ð™º + ð“‹â‚‚ð™¸.

    Let us define:

        ÏƒÂ²_g   = ð“‹â‚€(1-Ïâ‚€) (variance explained by persistent genetic effects)
        ÏƒÂ²_gxe = ð“‹â‚€Ïâ‚€     (variance explained by GxE effects)

        ÏƒÂ²_e   = ð“‹â‚Ïâ‚     (variance explained by environmental effects)
        ÏƒÂ²_k   = ð“‹â‚(1-Ïâ‚) (variance explained by population structure)
        ÏƒÂ²_n   = ð“‹â‚‚       (residual variance, noise)

    We set the total variance to sum up to 1:

        1 = ÏƒÂ²_g + ÏƒÂ²_gxe + ÏƒÂ²_e + ÏƒÂ²_k + ÏƒÂ²_n

    We set the variances explained by the non-genetic terms to be equal:

        v = ÏƒÂ²_e = ÏƒÂ²_k = ÏƒÂ²_n

    For `has_kinship=False`, we instead set the variances such that:

        v = ÏƒÂ²_e = ÏƒÂ²_n

    Parameters
    ----------
    r0 : float
        This is Ïâ‚€.
    v0 : float
        This is ð“‹â‚€.
    """
    v_g = v0 * (1 - r0)
    v_gxe = v0 * r0

    if has_kinship:
        v = (1 - v_gxe - v_g) / 3
        v_e = v
        v_k = v
        v_n = v
    else:
        v = (1 - v_gxe - v_g) / 2
        v_e = v
        v_n = v

    variances = {"g": v_g, "gxe": v_gxe, "e": v_e, "n": v_n}
    if has_kinship:
        variances["k"] = v_k
    else:
        variances["k"] = None

    return Variances(**variances)


def sample_persistent_effsizes(
    n_effects: int, causal_indices: list, variance: float, random
):
    """
    Let ðš“ denote a sample index and ðš” denote a SNP index. Let ðšŸâ±¼ = ð â±¼áµ€ð›ƒ.
    We assume that ð‘”â±¼â‚– is a random variable such that:

        ð”¼[ð‘”â±¼â‚–] = 0
        ð”¼[ð‘”â±¼â‚–Â²] = 1

    And we also assume that SNPs are uncorrelated from each other: ð”¼[ð‘”â±¼â‚–â‹…ð‘”â±¼áµ£] = 0
    for ðš”â‰ ðš›.
    Assuming that ð›ƒ is given (fixed), we want to simulate ð›ƒ such that:

        ð”¼[ðšŸâ±¼] = ð”¼[âˆ‘â‚–ð‘”â±¼â‚–ð›½â‚–] = âˆ‘â‚–ð”¼[ð‘”â±¼â‚–]ð›½â‚– = 0
        ð”¼[ðšŸâ±¼Â²] = ð”¼[(âˆ‘â‚–ð‘”â±¼â‚–ð›½â‚–)Â²] = âˆ‘â‚–ð”¼[ð‘”â±¼â‚–Â²]ð›½â‚–Â² = âˆ‘â‚–ð›½â‚–Â² = ð“‹.

    Let ðš’ denote a causal index. We initialize ð›ƒâ†ðŸŽ and then randomly set ð›½áµ¢Ïµ{-1,+1} for
    the causal SNPs. At last, we set ð›ƒâ†ð›ƒÃ—âˆš(ð“‹/ð˜¯) where ð˜¯ is the number of causal SNPs.
    This way we have âˆ‘â‚–ð›½â‚–Â² = ð“‹.

    Parameters
    ----------
    n_effects : int
        Number of effects.
    causal_indices : list
        List of causal SNPs.
    variance : float
        Correspond to ð“‹.
    """
    from numpy import errstate, sqrt, zeros

    n_causals = len(causal_indices)

    effsizes = zeros(n_effects)
    effsizes[causal_indices] = random.choice([+1, -1], size=len(causal_indices))
    with errstate(divide="raise", invalid="raise"):
        effsizes *= sqrt(variance / n_causals)

    return effsizes


def sample_persistent_effects(G, effsizes, variance: float):
    y_g = G @ effsizes
    _ensure_moments(y_g, 0, variance)
    return y_g


def sample_gxe_effects(G, E, causal_indices: list, variance: float, random):
    """
    Let ðš’ denote a SNP index and ðš“ denote an environment.
    Let ð‘¦â‚‚ = âˆ‘áµ¢(ð‘”áµ¢â‹…ð›œáµ€ðœ¶áµ¢) be the total GxE effect with

        ðœ¶áµ¢ âˆ¼ ð“(ðŸŽ, ðœŽáµ¢Â²I)

    for every SNP áµ¢.
    We have

        ð”¼[ð‘¦â‚‚] = âˆ‘áµ¢ð”¼[ð‘”áµ¢â‹…ð›œáµ€ðœ¶áµ¢] = âˆ‘áµ¢ð”¼[ð‘”áµ¢]ð”¼[ð›œáµ€ðœ¶áµ¢] = âˆ‘áµ¢0â‹…ð”¼[ð›œáµ€ðœ¶áµ¢] = 0,

    where ð‘”áµ¢ and ð›œáµ€ðœ¶áµ¢ are assumed to be uncorrelated.

    We also have

        ð”¼[ð‘¦â‚‚Â²] = ð”¼[(âˆ‘áµ¢ð‘”áµ¢â‹…ð›œáµ€ðœ¶áµ¢)Â²] = âˆ‘áµ¢âˆ‘â±¼ð”¼[ðœ–â±¼Â²]ð”¼[ð›¼áµ¢â±¼Â²] = âˆ‘áµ¢ðœŽáµ¢Â² = ðœŽÂ²,

    after a couple of assumptions.

    We define ðœŽáµ¢Â²=ð‘£áµ¢ if ð‘”áµ¢ is causal and ðœŽáµ¢Â²=0 otherwise. We assume all causal SNPs
    to have equal effect as defined by ð‘£áµ¢=ðœŽÂ²/ð‘›â‚‚, where ð‘›â‚‚ is the number of SNPs
    having GxE effects.

    We also assume that ð”¼[ðœ–â±¼]=0 and ð”¼[ðœ–â±¼Â²]=1/ð‘›â‚‘ for every environment ðš“.
    """
    from numpy import sqrt, zeros

    n_samples = G.shape[0]
    n_envs = E.shape[1]
    n_causals = len(causal_indices)
    vi = variance / n_causals

    y2 = zeros(n_samples)
    for causal in causal_indices:
        # ðœ¶áµ¢ âˆ¼ ð“(ðŸŽ, ðœŽáµ¢Â²I)
        alpha = sqrt(vi) * random.randn(n_envs)

        # Make the sample statistics close to population
        # statistics
        _ensure_moments(alpha, 0, sqrt(vi))

        # ðœ· = ð›œáµ€ðœ¶áµ¢
        beta = E @ alpha

        # ð‘”áµ¢â‹…ð›œáµ€ðœ¶áµ¢
        y2 += G[:, causal] * beta

    _ensure_moments(y2, 0, variance)

    return y2


# def sample_environment_effects(E, variance: float, random):
#     from numpy import sqrt

#     n_envs = E.shape[1]
#     effsizes = sqrt(variance) * random.randn(n_envs)
#     y3 = E @ effsizes

#     _ensure_moments(y3, 0, variance)

#     return y3


def sample_random_effect(K, variance: float, random):
    from numpy import zeros

    y = random.multivariate_normal(zeros(K.shape[0]), K)

    _ensure_moments(y, 0, variance)

    return y


def sample_noise_effects(n_samples: int, variance: float, random):
    from numpy import sqrt

    y5 = sqrt(variance) * random.randn(n_samples)
    _ensure_moments(y5, 0, variance)

    return y5


def sample_phenotype(
    offset: float,
    n_samples: int,
    n_snps: int,
    n_rep: int,
    n_env: int,
    n_env_groups: int,
    maf_min: float,
    maf_max: float,
    g_causals: list,
    gxe_causals: list,
    variances: Variances,
    random,
) -> Simulation:
    from numpy import ones, tile

    mafs = sample_maf(n_snps, maf_min, maf_max, random)

    G = sample_genotype(n_samples, mafs, random)
    G = tile(G, (n_rep, 1))
    G = column_normalize(G)
    E = create_environment_matrix(n_samples, n_rep, n_env, n_env_groups, random)

    Lk, K = sample_covariance_matrix(E.shape[0], n_samples)

    beta_g = sample_persistent_effsizes(n_snps, g_causals, variances.g, random)
    y_g = sample_persistent_effects(G, beta_g, variances.g)
    y_gxe = sample_gxe_effects(G, E, gxe_causals, variances.gxe, random)
    y_k = sample_random_effect(K, variances.k, random)
    y_e = sample_random_effect(E @ E.T, variances.e, random)
    y_n = sample_noise_effects(n_samples * n_rep, variances.n, random)

    M = ones((K.shape[0], 1))
    y = offset + y_g + y_gxe + y_k + y_e + y_n

    simulation = Simulation(
        mafs=mafs,
        offset=offset,
        beta_g=beta_g,
        y_g=y_g,
        y_gxe=y_gxe,
        y_k=y_k,
        y_e=y_e,
        y_n=y_n,
        y=y,
        variances=variances,
        Lk=Lk,
        K=K,
        E=E,
        G=G,
        M=M,
    )

    return simulation


def _ensure_moments(arr, mean: float, variance: float):
    from numpy import errstate, sqrt

    arr -= arr.mean(0) + mean
    with errstate(divide="raise", invalid="raise"):
        arr /= arr.std(0)
    arr *= sqrt(variance)
