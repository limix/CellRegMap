import sys

import numpy as np
from numpy import asarray, concatenate, eye, inf, newaxis, ones, sqrt, stack, zeros
from numpy.linalg import eigvalsh, inv, solve
from numpy.random import RandomState
from numpy_sugar.linalg import ddot, economic_qs, economic_svd
from scipy.linalg import sqrtm

from chiscore import davies_pvalue  # , mod_liu, optimal_davies_pvalue
from glimix_core.lmm import LMM
from struct_lmm import StructLMM

""" sample phenotype from the model:

	ð² = Wð›‚ + ð ð›½ + ð âŠ™ð›ƒ + ðž + u + ð›†

	ð›ƒ âˆ¼ ð“(ðŸŽ, bÂ²Î£)
    ðž âˆ¼ ð“(ðŸŽ, eÂ²Î£)
    ð›† âˆ¼ ð“(ðŸŽ, ðœ€Â²I)
    Î£ = EEáµ€
    u ~ ð“(ðŸŽ, gÂ²K)

"""

# Let Î£ = ð™´ð™´áµ€
# ð² âˆ¼ ð“(ð™¼ð›‚, ð“‹â‚€ð™³(ÏðŸðŸáµ€ + (1-Ï)Î£)ð™³ + ð“‹â‚(aÎ£ + (1-a)ð™º) + ð“‹â‚‚ð™¸).

seed = int(sys.argv[1])
random = RandomState(seed)  # set a seed to replicate simulations
# set sample size
n_samples = 500
# simulate MAF (minor allele frequency) distribution
maf_min = 0.35
maf_max = 0.45
n_snps = 20

print(n_samples, "samples")
print(n_snps, "snps")
print(maf_min, "min MAF")
print(maf_max, "max MAF")

"simulate environments"

# two groups
group_size = n_samples // 2

E = zeros((n_samples, 2))

E[:group_size, 0] = 1
E[group_size:, 1] = 1

Sigma = E @ E.T

# import pdb; pdb.set_trace()

"simulate genotypes (for n_snps variants)"


# Simulate genotypes (for n_snps variants)
mafs = random.rand(n_snps) * (maf_max - maf_min) + maf_min

# simulate SNPs accordingly
G = []

for maf in mafs:
    g = random.choice(
        [0, 1, 2],
        p=[(1 - maf) ** 2, 1 - ((1 - maf) ** 2 + maf ** 2), maf ** 2],
        size=n_samples,
    )
    G.append(asarray(g, float))

# We normalize it such that the expectation of ð”¼[ð áµ€ð ] = 1.
# i.e. normalize columns

G = stack(G, axis=1)
G -= G.mean(0)
G /= G.std(0)

G0 = G.copy()
G0 /= sqrt(G0.shape[1])
K = G0 @ G0.T


"simulate two SNPs to have persistent effects and two to have interaction effects"
"one SNP in common, one unique to each category"

idxs_persistent = [5, 6]
idxs_gxe = [10, 11]

print("MAFs of causal SNPs")

print("{}\t{}".format(idxs_persistent[0], mafs[idxs_persistent[0]]))
print("{}\t{}".format(idxs_persistent[1], mafs[idxs_persistent[1]]))
print("{}\t{}".format(idxs_gxe[0], mafs[idxs_gxe[0]]))
print("{}\t{}".format(idxs_gxe[1], mafs[idxs_gxe[1]]))

# idxs_persistent = [5, 30]
# idxs_gxe = [30, 45]

# Variances
#
# ð² âˆ¼ ð“(1 + âˆ‘áµ¢ð áµ¢ð›½_gáµ¢, ÏƒÂ²_gâ‹…ð™³ðŸðŸáµ€ð™³ + ÏƒÂ²_gxeâ‹…ð™³Î£ð™³ð™³ + ÏƒÂ²_eâ‹…Î£ + ÏƒÂ²_kâ‹…ð™º + ÏƒÂ²_nâ‹…ð™¸.
# ÏƒÂ²_g + ÏƒÂ²_gxe + ÏƒÂ²_e + ÏƒÂ²_k + ÏƒÂ²_n = 1
# ÏƒÂ²â‚*Ï + ÏƒÂ²â‚*(1-Ï) + ÏƒÂ²_e + ÏƒÂ²_k + ÏƒÂ²_n = 1

# The user will provide: ÏƒÂ²â‚, Ï
# And we assume that ÏƒÂ²_e = ÏƒÂ²_k = ÏƒÂ²_n = v
# v = (1 - ÏƒÂ²â‚*Ï + ÏƒÂ²â‚*(1-Ï)) / 3
# ÏƒÂ²_e = a*ÏƒÂ²â‚‚
# ÏƒÂ²_k = (1-a)*ÏƒÂ²â‚‚


"simulate sigma parameters"

rho = 0.8  # contribution of interactions (proportion)
var_tot_g_gxe = 0.9

print(rho, "rho (prop var explained by GxE)")
print(var_tot_g_gxe, "tot variance G + GxE")

var_tot_g = (1 - rho) * var_tot_g_gxe
var_tot_gxe = rho * var_tot_g_gxe

var_g = var_tot_g / len(idxs_persistent)  # split effect across n signals
var_gxe = var_tot_gxe / len(idxs_gxe)

v = (1 - var_tot_gxe - var_tot_g) / 3
var_e = v  # environment effect only
var_k = v  # population structure effect ?
var_noise = v
# print(v)

""" (persistent) genotype portion of phenotype:

	ð²_g = G ð›ƒ_g

	ð²_g = âˆ‘áµ¢ð áµ¢ð›½_gáµ¢,

 where ð áµ¢ is the i-th column of ð™¶.

"""


# simulate (persistent) beta to have causal SNPs as defined
beta_g = zeros(n_snps)
beta_g[idxs_persistent] = random.choice([+1, -1], size=len(idxs_persistent))
beta_g /= beta_g.std()
beta_g *= var_g

"calculate genoytpe component of y"

y_g = G @ beta_g


""" GxE portion of phenotype:

 	ð²_gxe = âˆ‘áµ¢ gáµ¢ x ð›ƒáµ¢

"""
# simulate (GxE) variance component to have causal SNPs as defined
sigma_gxe = zeros(n_snps)
sigma_gxe[idxs_gxe] = var_gxe

# for i in range(n_snps):
# 	print('{}\t{}'.format(i,sigma_gxe[i]))

y_gxe = zeros(n_samples)
u_gxe = ones(n_samples)
u_gxe[group_size:] = -1

for i in range(n_snps):
    # beta_gxe = random.multivariate_normal(zeros(n_samples), sigma_gxe[i] * Sigma)
    beta_gxe = sigma_gxe[i] * u_gxe
    y_gxe += G[:, i] * beta_gxe


e = random.multivariate_normal(zeros(n_samples), v * Sigma)
u = random.multivariate_normal(zeros(n_samples), v * K)
eps = random.multivariate_normal(zeros(n_samples), v * eye(n_samples))

e0 = random.multivariate_normal(zeros(n_samples), v * 3 / 2 * Sigma)
eps0 = random.multivariate_normal(zeros(n_samples), v * 3 / 2 * eye(n_samples))


"sum all parts of y"
y = 1 + y_g + y_gxe + e + u + eps
y0 = 1 + y_g + y_gxe + e0 + eps0


p_values0 = []
p_values1 = []
p_values2 = []
p_values3 = []

print("testing using standard structLMM")

"test using struct LMM (standard)"


y = y.reshape(y.shape[0], 1)

"Association test"

print(
    "p-values of association test SNPs",
    idxs_persistent,
    idxs_gxe,
    "should be causal (persistent + GxE)",
)

slmm = StructLMM(y0, M=np.ones(n_samples), E=E, W=E)
slmm.fit(verbose=False)

for i in range(n_snps):
    g = G[:, i]
    g = g.reshape(g.shape[0], 1)
    _p = slmm.score_2dof_assoc(g)
    print("{}\t{}".format(i, _p))
    p_values0.append(_p)

"Interaction test"

print("p-values of interaction test SNPs", idxs_gxe, "should be causal (GxE)")

for i in range(n_snps):
    g = G[:, i]
    # g = g.reshape(g.shape[0],1)
    M = np.ones(n_samples)
    M = np.stack([M, g], axis=1)
    slmm_int = StructLMM(y, M=M, E=E, W=E)
    null = slmm_int.fit(verbose=False)
    _p = slmm_int.score_2dof_inter(g)
    print("{}\t{}".format(i, _p))
    p_values1.append(_p)


################################################
################################################
################################################
################################################

print("using structLMM 2 now")

"test using struct LMM 2 (in this case it should not be very different)"

y = y.reshape(y.shape[0], 1)

Cov = {}
QS_a = {}

a_values = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]

for a in a_values:
    Cov[a] = a * Sigma + (1 - a) * K
    QS_a[a] = economic_qs(Cov[a])

"Association test"

print(
    "p-values of association test SNPs",
    idxs_persistent,
    idxs_gxe,
    "should be causal (persistent + GxE)",
)

for i in range(n_snps):
    g = G[:, i]
    g = g.reshape(g.shape[0], 1)
    best = {"lml": -inf, "a": 0, "v0": 0, "v1": 0, "beta": 0}
    for a in a_values:
        lmm = LMM(y, E, QS_a[a], restricted=True)  # cov(y) = v0*(aÎ£ + (1-a)K) + v1*Is
        lmm.fit(verbose=False)
        if lmm.lml() > best["lml"]:
            best["lml"] = lmm.lml()
            best["a"] = a
            best["v0"] = lmm.v0
            best["v1"] = lmm.v1
            best["alpha"] = lmm.beta

    "H0 optimal parameters"
    alpha = lmm.beta[:-1]
    beta = lmm.beta[-1]
    s2 = lmm.v0  # sÂ²
    eps2 = lmm.v1  # ðœ€Â²

    "H1 via score test"
    K0 = lmm.covariance()

"Interaction test"


print("p-values of interaction test SNPs", idxs_gxe, "should be causal (GxE)")

for i in range(n_snps):
    g = G[:, i]
    # import pdb; pdb.set_trace()
    g = g.reshape(g.shape[0], 1)
    # X = np.stack([E,g], axis = 1)
    X = concatenate((E, g), axis=1)
    best = {"lml": -inf, "a": 0, "v0": 0, "v1": 0, "beta": 0}
    for a in a_values:
        lmm = LMM(y, X, QS_a[a], restricted=True)  # cov(y) = v0*(aÎ£ + (1-a)K) + v1*Is
        lmm.fit(verbose=False)
        if lmm.lml() > best["lml"]:
            best["lml"] = lmm.lml()
            best["a"] = a
            best["v0"] = lmm.v0
            best["v1"] = lmm.v1
            best["alpha"] = lmm.beta

            # import pdb; pdb.set_trace()

    "H0 optimal parameters"
    alpha = lmm.beta[:-1]
    beta = lmm.beta[-1]
    # eÂ²Î£ + gÂ²K = sÂ²(aÎ£ + (1-a)K)
    # eÂ² = sÂ²*a
    # gÂ² = sÂ²*(1-a)
    s2 = lmm.v0  # sÂ²
    eps2 = lmm.v1  # ðœ€Â²

    "H1 via score test"
    # Let Kâ‚€ = gÂ²K + eÂ²Î£ + ðœ€Â²I
    # with optimal values eÂ² and ðœ€Â² found above.
    K0 = lmm.covariance()

    # Let Pâ‚€ = Kâ»Â¹ - Kâ‚€â»Â¹X(Xáµ€Kâ‚€â»Â¹X)â»Â¹Xáµ€Kâ‚€â»Â¹.
    K0iX = solve(K0, X)
    P0 = inv(K0) - K0iX @ solve(X.T @ K0iX, K0iX.T)

    # Pâ‚€ð² = Kâ»Â¹ð² - Kâ‚€â»Â¹X(Xáµ€Kâ‚€â»Â¹X)â»Â¹Xáµ€Kâ‚€â»Â¹ð².
    K0iy = solve(K0, y)
    P0y = K0iy - solve(K0, X @ solve(X.T @ K0iX, X.T @ K0iy))

    # The covariance matrix of H1 is K = Kâ‚€ + bÂ²diag(ð )â‹…Î£â‹…diag(ð )
    # We have âˆ‚K/âˆ‚bÂ² = diag(ð )â‹…Î£â‹…diag(ð )
    # The score test statistics is given by
    # Q = Â½ð²áµ€Pâ‚€â‹…âˆ‚Kâ‹…Pâ‚€ð²
    dK = ddot(g.ravel(), ddot(Sigma, g.ravel()))
    Q = (P0y.T @ dK @ P0y) / 2

    # Q is the score statistic for our interaction test and follows a linear combination
    # of chi-squared (df=1) distributions:
    # Q âˆ¼ âˆ‘Î»Ï‡Â², where Î»áµ¢ are the non-zero eigenvalues of Â½âˆšPâ‚€â‹…âˆ‚Kâ‹…âˆšPâ‚€.
    sqrP0 = sqrtm(P0)
    # lambdas = eigvalsh((sqrP0 @ dK @ sqrP0) / 2)
    # lambdas = lambdas[lambdas > epsilon.small]
    # print(lambdas)
    # print(Q)
    pval = davies_pvalue(Q, (sqrP0 @ dK @ sqrP0) / 2)
    print("{}\t{}".format(i, pval))
    p_values3.append(pval)
