"""
Mixed-model with genetic effect heterogeneity.

The extended StructLMM model is ::

    ð² = Wð›‚ + ð ð›½ + ð âŠ™ð›ƒ + ðž + u + ð›†,

where ::

    ð âŠ™ð›ƒ = âˆ‘áµ¢ð áµ¢ð›½áµ¢
    ð›ƒ âˆ¼ ð“(ðŸŽ, bÂ²Î£)
    ðž âˆ¼ ð“(ðŸŽ, eÂ²Î£)
    ð›† âˆ¼ ð“(ðŸŽ, ðœ€Â²I)
    Î£ = EEáµ€
    u ~ ð“(ðŸŽ, gÂ²K)

If one considers ð›½ âˆ¼ ð“(0, pÂ²), we can insert
ð›½ into ð›ƒ ::

    ð›ƒ_ âˆ¼ ð“(ðŸŽ, pÂ²ðŸðŸáµ€ + bÂ²Î£)

"""
from numpy import concatenate, inf, newaxis
from numpy.linalg import eigvalsh, inv, solve
from numpy.random import RandomState
from numpy_sugar import epsilon
from numpy_sugar.linalg import ddot, economic_qs
from scipy.linalg import sqrtm

from glimix_core.lmm import LMM

random = RandomState(0)
n = 30
c = 2

y = random.randn(n)
W = random.randn(n, c)
g = random.randn(n)
E = random.randn(n, 4)
Sigma = E @ E.T

# ð² = Wð›‚ + ð ð›½ + ð âŠ™ð›ƒ + ðž + ð›†,
# ðž âˆ¼ ð“(ðŸŽ, eÂ²Î£)
# Î£ = EEáµ€
QS = economic_qs(Sigma)

# ð² = Wð›‚ + ðž + ð›†
# ð“(ð² | Wð›‚, eÂ²Î£ + ðœ€Â²I)

"""
Interaction test
----------------
H0: bÂ² = 0 => ð² = Wð›‚ + ð ð›½ + ðž + u + ð›†
    ð² âˆ¼ ð“(Wð›‚ + ð ð›½, eÂ²Î£ + gÂ²K + ðœ€Â²I)
H1: bÂ² > 0 => ð² = Wð›‚ + ð ð›½ + ð âŠ™ð›ƒ + ðž + u + ð›†
    ð² âˆ¼ ð“(Wð›‚ + ð ð›½, eÂ²Î£ + gÂ²K + ðœ€Â²I + bÂ²Î£)
"""
X = concatenate((W, g[:, newaxis]), axis=1)
lmm = LMM(y, X, QS)
lmm.fit(verbose=False)

best = {"lml": -inf, "a": 0, "v0": 0, "v1": 0, "beta": 0}
for a in [0.1, 0.5, 0.9]:
    # cov(y) = v0*(aÎ£ + (1-a)K) + v1*I
    QS = economic_qs(a * Sigma + (1 - a) * K)
    lmm = LMM(y, X, QS)
    lmm.fit(verbose=False)
    if lmm.lml() > best["lml"]:
        best["lml"] = lmm.lml()
        best["a"] = a
        best["v0"] = lmm.v0
        best["v1"] = lmm.v1
        best["alpha"] = lmm.beta

# The way LMM represents: ð“(y|Xb, scale * ((1-Î´)K  + Î´I))
# lmm.delta = 0.1
# lmm.scale = 3.4
# lmm.fix("scale")
# lmm.fix("delta")

# H0 optimal parameters
alpha = lmm.beta[:-1]
beta = lmm.beta[-1]
# eÂ²Î£ + gÂ²K = sÂ²(aÎ£ + (1-a)K)
# eÂ² = sÂ²*a
# gÂ² = sÂ²*(1-a)
s2 = lmm.v0  # sÂ²
eps2 = lmm.v1  # ðœ€Â²

# H1 via score test
# Let Kâ‚€ = gÂ²K + eÂ²Î£ + ðœ€Â²I
# with optimal values eÂ² and ðœ€Â² found above.
K0 = lmm.covariance()

# Let Pâ‚€ = Kâ»Â¹ - Kâ‚€â»Â¹X(Xáµ€Kâ‚€â»Â¹X)â»Â¹Xáµ€Kâ‚€â»Â¹.
K0iX = solve(K0, X)
P0 = inv(K0) - K0iX @ solve(X.T @ K0iX, K0iX.T)

# Pâ‚€ð² = Kâ»Â¹ð² - Kâ‚€â»Â¹X(Xáµ€Kâ‚€â»Â¹X)â»Â¹Xáµ€Kâ‚€â»Â¹ð².
K0iy = solve(K0, y)
P0y = K0iy - solve(K0, X @ solve(X.T @ K0iX, X.T @ K0iy))

# The covariance matrix of H1 is K = Kâ‚€ + bÂ²diag(ð )â‹…Î£â‹…diag(ð )
# We have âˆ‚K/âˆ‚bÂ² = diag(ð )â‹…Î£â‹…diag(ð )
# The score test statistics is given by
# Q = Â½ð²áµ€Pâ‚€â‹…âˆ‚Kâ‹…Pâ‚€ð²
dK = ddot(g, ddot(Sigma, g))
Q = (P0y.T @ dK @ P0y) / 2

# Q is the score statistic for our interaction test and follows a linear combination
# of chi-squared (df=1) distributions:
# Q âˆ¼ âˆ‘Î»Ï‡Â², where Î»áµ¢ are the non-zero eigenvalues of Â½âˆšPâ‚€â‹…âˆ‚Kâ‹…âˆšPâ‚€.
sqrP0 = sqrtm(P0)
lambdas = eigvalsh((sqrP0 @ dK @ sqrP0) / 2)
lambdas = lambdas[lambdas > epsilon.small]
print(lambdas)
print(Q)
