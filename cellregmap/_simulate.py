from collections import namedtuple
from typing import List, Union

from numpy import (
    array_split,
    asarray,
    cumsum,
    errstate,
    eye,
    isscalar,
    ones,
    repeat,
    split,
    sqrt,
    stack,
    zeros,
)
from numpy.random import Generator
from numpy_sugar import ddot
from numpy_sugar.linalg import economic_svd

from ._types import Term

Variances = namedtuple("Variances", "g gxe k e n")
Simulation = namedtuple(
    "Simulation", "mafs y offset beta_g y_g y_gxe y_k y_e y_n variances G E Lk Ls K M"
)
SimulationFixedGxE = namedtuple(
    "Simulation",
    "mafs y offset beta_g beta_gxe beta_e y_g y_gxe y_k y_e y_n variances G E Lk K M",
)


def sample_maf(n_snps: int, maf_min: float, maf_max: float, random: Generator):
    assert maf_min <= maf_max and maf_min >= 0 and maf_max <= 1
    return random.random(n_snps) * (maf_max - maf_min) + maf_min


def sample_genotype(n_samples: int, mafs, random):
    G = []
    mafs = asarray(mafs, float)
    for maf in mafs:
        probs = [(1 - maf) ** 2, 1 - ((1 - maf) ** 2 + maf ** 2), maf ** 2]
        g = random.choice([0, 1, 2], p=probs, size=n_samples)
        G.append(asarray(g, float))

    return stack(G, axis=1)


def column_normalize(X):
    X = asarray(X, float)

    with errstate(divide="raise", invalid="raise"):
        return (X - X.mean(0)) / X.std(0)


def create_environment_matrix(
    n_samples: int, n_env: int, groups: List[List[int]], random: Generator
):
    E = random.normal(size=[n_samples, n_env])
    E = column_normalize(E)
    EE = E @ E.T
    EE /= EE.diagonal().mean()
    H = sample_covariance_matrix(n_samples, groups)[1]
    M = EE + H
    M /= M.diagonal().mean()
    jitter(M)
    return _symmetric_decomp(M)


def create_environment_vector(
    n_samples: int, groups: List[List[int]], random: Generator
):
    E = zeros((n_samples, 1))

    values = random.choice([-1, 1], 2, False)
    for value, group in zip(values, groups):
        E[group, 0] = value

    return E


def sample_covariance_matrix(n_samples: int, groups: List[List[int]]):
    X = zeros((n_samples, len(groups)))

    for i, idx in enumerate(groups):
        X[idx, i] = 1.0

    K = X @ X.T
    K /= K.diagonal().mean()
    jitter(K)

    return (_symmetric_decomp(K), K)


def jitter(K):
    with errstate(divide="raise", invalid="raise"):
        # This small diagonal offset is to guarantee the full-rankness.
        K += 1e-8 * eye(K.shape[0])

    return K


def create_variances(r0, v0, has_kinship=True) -> Variances:
    """
    Remember that:

        cov(ð²) = ð“‹â‚€(1-Ïâ‚€)ð™³ðŸðŸáµ€ð™³ + ð“‹â‚€Ïâ‚€ð™³ð™´ð™´áµ€ð™³ + ð“‹â‚Ïâ‚EEáµ€ + ð“‹â‚(1-Ïâ‚)ð™º + ð“‹â‚‚ð™¸.

    Let us define:

        ÏƒÂ²_g   = ð“‹â‚€(1-Ïâ‚€) (variance explained by persistent genetic effects)
        ÏƒÂ²_gxe = ð“‹â‚€Ïâ‚€     (variance explained by GxE effects)

        ÏƒÂ²_e   = ð“‹â‚Ïâ‚     (variance explained by environmental effects)
        ÏƒÂ²_k   = ð“‹â‚(1-Ïâ‚) (variance explained by population structure)
        ÏƒÂ²_n   = ð“‹â‚‚       (residual variance, noise)

    We set the total variance to sum up to 1:

        1 = ÏƒÂ²_g + ÏƒÂ²_gxe + ÏƒÂ²_e + ÏƒÂ²_k + ÏƒÂ²_n

    We set the variances explained by the non-genetic terms to be equal:

        v = ÏƒÂ²_e = ÏƒÂ²_k = ÏƒÂ²_n

    For `has_kinship=False`, we instead set the variances such that:

        v = ÏƒÂ²_e = ÏƒÂ²_n

    Parameters
    ----------
    r0 : float
        This is Ïâ‚€.
    v0 : float
        This is ð“‹â‚€.
    """
    v_g = v0 * (1 - r0)
    v_gxe = v0 * r0

    v_k = 0.0
    if has_kinship:
        v = (1 - v_gxe - v_g) / 3
        v_e = v
        v_k = v
        v_n = v
    else:
        v = (1 - v_gxe - v_g) / 2
        v_e = v
        v_n = v

    variances = {"g": v_g, "gxe": v_gxe, "e": v_e, "n": v_n}
    if has_kinship:
        variances["k"] = v_k
    else:
        variances["k"] = None

    return Variances(**variances)


def sample_persistent_effsizes(
    n_effects: int, causal_indices: list, variance: float, random: Generator
):
    """
    Let ðš“ denote a sample index and ðš” denote a SNP index. Let ðšŸâ±¼ = ð â±¼áµ€ð›ƒ.
    We assume that ð‘”â±¼â‚– is a random variable such that:

        ð”¼[ð‘”â±¼â‚–] = 0
        ð”¼[ð‘”â±¼â‚–Â²] = 1

    And we also assume that SNPs are uncorrelated from each other: ð”¼[ð‘”â±¼â‚–â‹…ð‘”â±¼áµ£] = 0
    for ðš”â‰ ðš›.
    Assuming that ð›ƒ is given (fixed), we want to simulate ð›ƒ such that:

        ð”¼[ðšŸâ±¼] = ð”¼[âˆ‘â‚–ð‘”â±¼â‚–ð›½â‚–] = âˆ‘â‚–ð”¼[ð‘”â±¼â‚–]ð›½â‚– = 0
        ð”¼[ðšŸâ±¼Â²] = ð”¼[(âˆ‘â‚–ð‘”â±¼â‚–ð›½â‚–)Â²] = âˆ‘â‚–ð”¼[ð‘”â±¼â‚–Â²]ð›½â‚–Â² = âˆ‘â‚–ð›½â‚–Â² = ð“‹.

    Let ðš’ denote a causal index. We initialize ð›ƒâ†ðŸŽ and then randomly set ð›½áµ¢Ïµ{-1,+1} for
    the causal SNPs. At last, we set ð›ƒâ†ð›ƒÃ—âˆš(ð“‹/ð˜¯) where ð˜¯ is the number of causal SNPs.
    This way we have âˆ‘â‚–ð›½â‚–Â² = ð“‹.

    Parameters
    ----------
    n_effects : int
        Number of effects.
    causal_indices : list
        List of causal SNPs.
    variance : float
        Correspond to ð“‹.
    """
    n_causals = len(causal_indices)

    effsizes = zeros(n_effects)
    if variance == 0.0:
        return effsizes

    effsizes[causal_indices] = random.choice([+1, -1], size=len(causal_indices))
    with errstate(divide="raise", invalid="raise"):
        effsizes *= sqrt(variance / n_causals)

    return effsizes


def sample_persistent_effects(X, effsizes, variance: float):
    y_g = X @ effsizes
    if variance > 0:
        _ensure_moments(y_g, 0, variance)
    return y_g


def sample_gxe_effects(G, E, causal_indices: list, variance: float, random: Generator):
    """
    Let ðš’ denote a SNP index and ðš“ denote an environment.
    Let ð‘¦â‚‚ = âˆ‘áµ¢(ð‘”áµ¢â‹…ð›œáµ€ðœ¶áµ¢) be the total GxE effect with

        ðœ¶áµ¢ âˆ¼ ð“(ðŸŽ, ðœŽáµ¢Â²I)

    for every SNP áµ¢.
    We have

        ð”¼[ð‘¦â‚‚] = âˆ‘áµ¢ð”¼[ð‘”áµ¢â‹…ð›œáµ€ðœ¶áµ¢] = âˆ‘áµ¢ð”¼[ð‘”áµ¢]ð”¼[ð›œáµ€ðœ¶áµ¢] = âˆ‘áµ¢0â‹…ð”¼[ð›œáµ€ðœ¶áµ¢] = 0,

    where ð‘”áµ¢ and ð›œáµ€ðœ¶áµ¢ are assumed to be uncorrelated.

    We also have

        ð”¼[ð‘¦â‚‚Â²] = ð”¼[(âˆ‘áµ¢ð‘”áµ¢â‹…ð›œáµ€ðœ¶áµ¢)Â²] = âˆ‘áµ¢âˆ‘â±¼ð”¼[ðœ–â±¼Â²]ð”¼[ð›¼áµ¢â±¼Â²] = âˆ‘áµ¢ðœŽáµ¢Â² = ðœŽÂ²,

    after a couple of assumptions.

    We define ðœŽáµ¢Â²=ð‘£áµ¢ if ð‘”áµ¢ is causal and ðœŽáµ¢Â²=0 otherwise. We assume all causal SNPs
    to have equal effect as defined by ð‘£áµ¢=ðœŽÂ²/ð‘›â‚‚, where ð‘›â‚‚ is the number of SNPs
    having GxE effects.

    We also assume that ð”¼[ðœ–â±¼]=0 and ð”¼[ðœ–â±¼Â²]=1/ð‘›â‚‘ for every environment ðš“.
    """
    n_samples = G.shape[0]
    n_envs = E.shape[1]
    n_causals = len(causal_indices)

    y2 = zeros(n_samples)
    if variance == 0.0:
        return y2

    vi = variance / n_causals
    for causal in causal_indices:
        # ðœ¶áµ¢ âˆ¼ ð“(ðŸŽ, ðœŽáµ¢Â²I)
        alpha = sqrt(vi) * random.normal(size=n_envs)

        # Make the sample statistics close to population
        # statistics
        if n_envs > 1:
            _ensure_moments(alpha, 0, sqrt(vi))

        # ðœ· = ð›œáµ€ðœ¶áµ¢
        beta = E @ alpha

        # ð‘”áµ¢â‹…ð›œáµ€ðœ¶áµ¢
        y2 += G[:, causal] * beta

    _ensure_moments(y2, 0, variance)

    return y2


# def sample_environment_effects(E, variance: float, random):
#     from numpy import sqrt

#     n_envs = E.shape[1]
#     effsizes = sqrt(variance) * random.randn(n_envs)
#     y3 = E @ effsizes

#     _ensure_moments(y3, 0, variance)

#     return y3


# def sample_random_effect(K, variance: float, random: Generator):
#     y = random.multivariate_normal(zeros(K.shape[0]), K, method="cholesky")

#     _ensure_moments(y, 0, variance)

#     return y

def _sample_random_effect(X, variance: float, random: Generator):
    u = sqrt(variance) * random.normal(size=X.shape[1])
    y = X @ u

    _ensure_moments(y, 0, variance)

    return y


def sample_random_effect(X, variance: float, random: Generator):
    if not isinstance(X, tuple):
        return _sample_random_effect(X, variance, random)

    n = X[0].shape[0]
    y = zeros(n)
    for L in X:
        u = sqrt(variance) * random.normal(size=L.shape[1])
        y += L @ u
    _ensure_moments(y, 0, variance)

    return y


def sample_noise_effects(n_samples: int, variance: float, random: Generator):
    y5 = sqrt(variance) * random.normal(size=n_samples)
    _ensure_moments(y5, 0, variance)

    return y5


def sample_phenotype_gxe(
    offset: float,
    n_individuals: int,
    n_snps: int,
    n_cells: Union[int, List[int]],
    n_env_groups: int,
    maf_min: float,
    maf_max: float,
    g_causals: list,
    gxe_causals: list,
    variances: Variances,
    random: Generator,
    env_term: Term = Term.RANDOM,
) -> Simulation:
    """
    Parameters
    ----------
    n_cells
         Integer number of array of integers.
    """
    mafs = sample_maf(n_snps, maf_min, maf_max, random)

    G = sample_genotype(n_individuals, mafs, random)
    G = repeat(G, n_cells, axis=0)
    G = column_normalize(G)

    n_samples = G.shape[0]

    if isscalar(n_cells):
        individual_groups = array_split(range(n_samples), n_individuals)
    else:
        individual_groups = split(range(n_samples), cumsum(n_cells))[:-1]

    env_groups = array_split(random.permutation(range(n_samples)), n_env_groups)

    E = sample_covariance_matrix(n_samples, env_groups)[0]

    Lk, K = sample_covariance_matrix(n_samples, individual_groups)
    [U, S, _] = economic_svd(E)
    us = U * S
    Ls = tuple([ddot(us[:, i], Lk) for i in range(us.shape[1])])

    beta_g = sample_persistent_effsizes(n_snps, g_causals, variances.g, random)
    y_g = sample_persistent_effects(G, beta_g, variances.g)

    y_gxe = sample_gxe_effects(G, E, gxe_causals, variances.gxe, random)

    y_k = sample_random_effect(Ls, variances.k, random)

    if env_term is Term.RANDOM:
        y_e = sample_random_effect(E, variances.e, random)
    elif env_term is Term.FIXED:
        n = E.shape[1]
        beta_e = sample_persistent_effsizes(n, list(range(n)), variances.e, random)
        y_e = sample_persistent_effects(E, beta_e, variances.e)
    else:
        raise ValueError("Invalid term.")

    y_n = sample_noise_effects(n_samples, variances.n, random)

    M = ones((K.shape[0], 1))
    y = offset + y_g + y_gxe + y_k + y_e + y_n

    simulation = Simulation(
        mafs=mafs,
        offset=offset,
        beta_g=beta_g,
        y_g=y_g,
        y_gxe=y_gxe,
        y_k=y_k,
        y_e=y_e,
        y_n=y_n,
        y=y,
        variances=variances,
        Lk=Lk,
        Ls=Ls,
        K=K,
        E=E,
        G=G,
        M=M,
    )

    return simulation


def sample_phenotype(
    offset: float,
    n_individuals: int,
    n_snps: int,
    n_cells: Union[int, List[int]],
    n_env: int,
    n_env_groups: int,
    maf_min: float,
    maf_max: float,
    g_causals: list,
    gxe_causals: list,
    variances: Variances,
    random: Generator,
) -> Simulation:
    """
    Parameters
    ----------
    n_cells
         Integer number of array of integers.
    """
    mafs = sample_maf(n_snps, maf_min, maf_max, random)

    G = sample_genotype(n_individuals, mafs, random)
    G = repeat(G, n_cells, axis=0)
    G = column_normalize(G)

    n_samples = G.shape[0]
    individual_groups = array_split(range(n_samples), n_individuals)

    env_groups = array_split(random.permutation(range(n_samples)), n_env_groups)
    E = create_environment_matrix(n_samples, n_env, env_groups, random)

    Lk, K = sample_covariance_matrix(n_samples, individual_groups)

    beta_g = sample_persistent_effsizes(n_snps, g_causals, variances.g, random)

    y_g = sample_persistent_effects(G, beta_g, variances.g)

    y_gxe = sample_gxe_effects(G, E, gxe_causals, variances.gxe, random)

    y_k = sample_random_effect(Lk, variances.k, random)

    y_e = sample_random_effect(E, variances.e, random)

    y_n = sample_noise_effects(n_samples, variances.n, random)

    M = ones((K.shape[0], 1))
    y = offset + y_g + y_gxe + y_k + y_e + y_n

    simulation = Simulation(
        mafs=mafs,
        offset=offset,
        beta_g=beta_g,
        y_g=y_g,
        y_gxe=y_gxe,
        y_k=y_k,
        y_e=y_e,
        y_n=y_n,
        y=y,
        variances=variances,
        Lk=Lk,
        K=K,
        E=E,
        G=G,
        M=M,
    )

    return simulation


def _ensure_moments(arr, mean: float, variance: float):
    arr -= arr.mean(0) + mean
    with errstate(divide="raise", invalid="raise"):
        arr /= arr.std(0)
    arr *= sqrt(variance)


def _symmetric_decomp(H):
    [U, S, _] = economic_svd(H)
    return ddot(U, sqrt(S))
